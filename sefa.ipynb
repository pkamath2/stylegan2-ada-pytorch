{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "from typing import List, Optional\n",
    "\n",
    "import click\n",
    "import dnnlib\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import legacy\n",
    "\n",
    "import librosa\n",
    "import librosa.display\n",
    "import soundfile as sf\n",
    "\n",
    "from tifresi.utils import load_signal\n",
    "from tifresi.utils import preprocess_signal\n",
    "from tifresi.stft import GaussTF, GaussTruncTF\n",
    "from tifresi.transforms import log_spectrogram\n",
    "from tifresi.transforms import inv_log_spectrogram\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "import warnings\n",
    "import matplotlib.cbook\n",
    "warnings.filterwarnings(\"ignore\",category=matplotlib.cbook.mplDeprecation)\n",
    "\n",
    "from IPython.display import Audio \n",
    "import IPython\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_channels = 512\n",
    "n_frames = 256\n",
    "hop_size = 128\n",
    "sample_rate = 16000\n",
    "\n",
    "def pghi_istft(x):\n",
    "    use_truncated_window = True\n",
    "    if use_truncated_window:\n",
    "        stft_system = GaussTruncTF(hop_size=hop_size, stft_channels=stft_channels)\n",
    "    else:\n",
    "        stft_system = GaussTF(hop_size=hop_size, stft_channels=stft_channels)\n",
    "\n",
    "    x = np.squeeze(x,axis=0)\n",
    "    new_Y = inv_log_spectrogram(x)\n",
    "    new_y = stft_system.invert_spectrogram(new_Y)\n",
    "    return new_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GreatestHits\n",
    "checkpoint_num = '2200'\n",
    "network_pkl = 'training-runs/00041-vis-data-256-split-auto1-noaug/network-snapshot-00{checkpoint_num}.pkl'.format(checkpoint_num=checkpoint_num)\n",
    "output_dir = 'sefa-results/greatesthits/sefa-00041-{checkpoint_num}'.format(checkpoint_num=checkpoint_num)\n",
    "\n",
    "#TokWotel\n",
    "# checkpoint_num = '0200'\n",
    "# network_pkl = 'training-runs/00040-tokwotel-auto1-noaug/network-snapshot-00{checkpoint_num}.pkl'.format(checkpoint_num=checkpoint_num)\n",
    "# output_dir = 'sefa-results/tokwotel/sefa-00040-{checkpoint_num}'.format(checkpoint_num=checkpoint_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['b4', 'b4', 'b8', 'b8', 'b16', 'b16', 'b32', 'b32', 'b64', 'b64', 'b128', 'b128', 'b256', 'b256']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "num_samples = 7\n",
    "num_semantics = 7\n",
    "distance_value = 5\n",
    "start_distance = -1.0*distance_value\n",
    "end_distance = 1.0*distance_value\n",
    "num_steps = 11\n",
    "distances = np.linspace(start_distance, end_distance, num_steps)\n",
    "\n",
    "\n",
    "layers = ['b4','b8','b16','b32','b64','b128','b256'] #layernames in Synthesis network\n",
    "# layers = ['b4','b8','b16','b32'] #layernames in Synthesis network\n",
    "# layers = ['b4','b8','b16']\n",
    "# layers = ['b16','b32','b64']\n",
    "# layers = ['b64','b128','b256'] #layernames in Synthesis network\n",
    "# layers = ['b8','b16','b32','b64'] #layernames in Synthesis network\n",
    "layers_identifier = '-'.join(layers)+'-'+str(distance_value)+'dist'+'-G'\n",
    "layers.extend(layers) ## THIS IS SUPER IMPORTANT. Remember, the dimensionality of y is twice the number of feature maps (see first Style GAN paper)\n",
    "layers.sort(key=lambda x: int(x.replace('b','')))\n",
    "print(layers)\n",
    "\n",
    "sefa_output_dir = os.path.join(output_dir, layers_identifier)\n",
    "sefa_output_audio_dir = os.path.join(sefa_output_dir, 'audio')\n",
    "os.makedirs(sefa_output_dir, exist_ok=True)\n",
    "os.makedirs(sefa_output_audio_dir, exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')\n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G = legacy.load_network_pkl(f)['G'].to(device).eval()\n",
    "    \n",
    "with dnnlib.util.open_url(network_pkl) as f:\n",
    "    G_ema = legacy.load_network_pkl(f)['G_ema'].to(device).eval()\n",
    "    \n",
    "generator = G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(128, 128) (128,)\n",
      "[138.17625427  83.62195587  80.00395203  77.82159424  76.91971588\n",
      "  75.88919067  74.14586639  73.17889404  70.00765991  68.87132263\n",
      "  68.37974548  68.07419586  67.04872894  65.73930359  64.77319336\n",
      "  64.22251892  63.7420311   62.47785568  62.1232872   61.59173965\n",
      "  61.15961838  59.89933014  59.53933716  59.04004288  58.66625214\n",
      "  58.45537186  57.56650925  56.87845612  56.6220932   56.16900253\n",
      "  55.30134201  55.15444183  54.95201492  54.40515518  53.87666321\n",
      "  53.28897858  52.83316422  52.18307495  52.0953331   51.51014328\n",
      "  50.99672318  50.49062729  49.9239006   49.6997261   49.2090683\n",
      "  48.56822205  48.34690857  48.03170776  47.24629211  46.78878784\n",
      "  46.36758804  45.79691315  45.29172516  44.97393036  44.85342789\n",
      "  43.9659462   43.59421539  42.97405243  42.86740112  42.49003601\n",
      "  41.81612015  41.35634995  40.58515167  40.48667145  40.2219429\n",
      "  39.52517319  38.50452805  38.13554001  37.80888367  37.39937592\n",
      "  37.26199722  36.71719742  36.04849625  35.58002472  35.02321625\n",
      "  34.19813538  33.97698975  32.81244659  32.42275238  31.64897919\n",
      "  31.35257339  30.60925293  29.70697403  29.29539108  28.60852432\n",
      "  27.40505028  26.97402     26.08944702  25.21005821  24.51921272\n",
      "  24.3098526   22.89442444  22.78080559  21.85934639  21.12047577\n",
      "  20.40540314  19.07760239  18.52878189  17.23200607  16.33431625\n",
      "  15.9508009   15.32100201  14.97844315  14.29181576  13.33760357\n",
      "  12.77043056  12.26483345  12.13285065  11.03875732  10.26977825\n",
      "  10.05508232   9.66447639   8.92130661   8.62882137   8.19130516\n",
      "   7.73416615   7.34796      7.16760921   6.70735693   6.46690989\n",
      "   6.21768236   5.48166943   5.13015938   4.71387005   4.13013554\n",
      "   3.47725844   2.77004981   2.1115365 ] [  0.   1.   2.   3.   4.   5.   6.   7.  14.  16.  24.  26.  28.  37.\n",
      "  38.  44.  45.  50.  51.  52.  53.  58.  59.  60.  66.  65.  68.  73.\n",
      "  72.  76.  77.  78.  80.  81.  85.  86.  87.  91.  92.  90.  96.  97.\n",
      "  98.  99. 122. 105. 106. 107. 127. 108. 111. 113. 118. 121. 120. 125.\n",
      " 117. 123. 119. 116. 124. 114. 115. 126. 112. 109. 102. 103. 104. 110.\n",
      " 101. 100.  95.  94.  93.  89.  88.  84.  83.  79.  82.  75.  74.  71.\n",
      "  70.  69.  67.  64.  63.  61.  62.  57.  56.  55.  54.  49.  48.  47.\n",
      "  46.  43.  42.  41.  40.  39.  36.  35.  34.  33.  32.  30.  31.  29.\n",
      "  27.  25.  23.  22.  21.  20.  19.  18.  17.  15.  13.  12.  11.  10.\n",
      "   9.   8.]\n"
     ]
    }
   ],
   "source": [
    "weights = []\n",
    "layer_ids = []\n",
    "for layer_id, layer_name in enumerate(layers):\n",
    "    weight = generator.synthesis.__getattr__(layer_name).__getattr__('torgb').affine.weight.T\n",
    "    weights.append(weight.cpu().detach().numpy())\n",
    "    layer_ids.append(layer_id)\n",
    "    \n",
    "weight = np.concatenate(weights, axis=1).astype(np.float32)\n",
    "weight = weight / np.linalg.norm(weight, axis=0, keepdims=True)\n",
    "eigen_values, eigen_vectors = np.linalg.eig(weight.dot(weight.T))\n",
    "boundaries, values = eigen_vectors.T, eigen_values\n",
    "\n",
    "print(boundaries.shape, values.shape)\n",
    "\n",
    "#Sorting values\n",
    "values_ind = np.array([a for a in range(len(values))])\n",
    "temp = np.array(sorted(zip(values, values_ind), key=lambda x: x[0], reverse=True))\n",
    "values, values_ind = temp[:, 0], temp[:, 1]\n",
    "\n",
    "print(values, values_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"bias_act_plugin\"... Done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(7, 14, 128)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# np.random.seed(987348234)\n",
    "# torch.manual_seed(987348234)\n",
    "\n",
    "# Prepare codes.\n",
    "codes = torch.randn(num_samples, generator.z_dim).cuda()\n",
    "codes = generator.mapping(codes, None)#['w']\n",
    "codes = codes.detach().cpu().numpy()\n",
    "codes.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up PyTorch plugin \"upfirdn2d_plugin\"... Done.\n"
     ]
    }
   ],
   "source": [
    "for sample_id in range(num_samples):\n",
    "    code = codes[sample_id:sample_id + 1]\n",
    "    \n",
    "    for semantic_id in range(num_semantics):\n",
    "        \n",
    "        val_sorted_ind = int(values_ind[semantic_id])\n",
    "        \n",
    "        boundary = boundaries[val_sorted_ind:val_sorted_ind + 1]\n",
    "        \n",
    "        for dist_id, dist in enumerate(distances, start=1):\n",
    "            temp_code = code.copy()\n",
    "            temp_code[:, layer_ids, :] += boundary * dist\n",
    "            image = generator.synthesis(torch.from_numpy(temp_code).cuda())\n",
    "            image = (image  * 127.5+ 128).clamp(0, 255).to(torch.uint8)\n",
    "            image = image.detach().cpu().numpy()[0]\n",
    "\n",
    "            filler = np.full((1, 1, image[0][0].shape[0]), np.min(image))\n",
    "            image = np.append(image, filler, axis=1) # UNDOING THAT CODE!\n",
    "            image = image/255\n",
    "            image = -50+image*50\n",
    "            \n",
    "            audio = pghi_istft(image)\n",
    "            \n",
    "            filename = 'samplenum_'+str(sample_id)+'_semantic_'+str(semantic_id)+'_distance_'+str(dist)+'.wav'\n",
    "            sf.write(os.path.join(sefa_output_audio_dir, filename), audio.astype(float), sample_rate)\n",
    "            \n",
    "            fig=plt.figure()\n",
    "            filename_img = 'samplenum_'+str(sample_id)+'_semantic_'+str(semantic_id)+'_distance_'+str(dist)+'.png'\n",
    "            _=librosa.display.specshow(image[0], y_axis='log', sr=sample_rate, x_axis='time')\n",
    "            code_sematic_specpng_path = os.path.join(sefa_output_audio_dir, filename_img)\n",
    "            plt.savefig(code_sematic_specpng_path)\n",
    "            plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_html_template_str = '''<html>\n",
    "    <head>\n",
    "        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n",
    "\n",
    "        <meta charset=\"utf-8\">\n",
    "        <meta name=\"viewport\" content=\"width=device-width, initial-scale=1, shrink-to-fit=yes\">\n",
    "        <link rel=\"preconnect\" href=\"https://fonts.gstatic.com\">\n",
    "        <link\n",
    "            href=\"https://fonts.googleapis.com/css2?family=Open+Sans:ital,wght@0,300;0,400;0,600;0,700;0,800;1,300;1,400;1,600;1,700;1,800&display=swap\"\n",
    "            rel=\"stylesheet\">\n",
    "        <link href=\"https://cdn.jsdelivr.net/npm/bootstrap@5.0.0-beta2/dist/css/bootstrap.min.css\" rel=\"stylesheet\"\n",
    "            integrity=\"sha384-BmbxuPwQa2lc/FVzBcNJ7UAyJxM6wuqIj61tLrc4wSX0szH/Ev+nYRRuWlolflfl\" crossorigin=\"anonymous\">\n",
    "    </head>\n",
    "    <body>\n",
    "\n",
    "        {html_data}\n",
    "\n",
    "    </body>\n",
    "</html>'''\n",
    "\n",
    "header_template_str = '''\n",
    "<div class='row'>\n",
    "{header_row}\n",
    "</div>\n",
    "'''\n",
    "\n",
    "header_template_first_col_str = '''\n",
    "<div class='col-1 border'>({semantic_id}) Semantic ({semantic_val})</div>\n",
    "'''\n",
    "\n",
    "header_template_remaining_col_str = '''\n",
    "<div class='col-1 border'>Direction ({direction_val})</div>\n",
    "'''\n",
    "\n",
    "\n",
    "sample_template_str = '''\n",
    "<div class='row text-wrap'>\n",
    "{sample_row}\n",
    "</div>\n",
    "'''\n",
    "\n",
    "sample_template_first_col_str = '''\n",
    "<div class='col-1 border text-wrap'>Sample ({sample_id})</div>\n",
    "'''\n",
    "\n",
    "\n",
    "sample_template_remaining_col_str = '''\n",
    "<div class='col-1 border text-wrap'>\n",
    "    <img width='100%' src='audio/samplenum_{sample_id}_semantic_{semantic_id}_distance_{dist}.png'/><br/>\n",
    "    <audio  style='width:100%' controls>\n",
    "        <source src='audio/samplenum_{sample_id}_semantic_{semantic_id}_distance_{dist}.wav' type='audio/wav'/>\n",
    "    </audio>\n",
    "</div>\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "body_html = ''\n",
    "for sem_id in range(num_semantics):\n",
    "    \n",
    "    header_inner_html = header_template_first_col_str.format(semantic_val='{:.2f}'.format(values[sem_id]), semantic_id=int(sem_id)+1)\n",
    "    \n",
    "    for dist_id, dist in enumerate(distances, start=1):\n",
    "        header_inner_html = header_inner_html + header_template_remaining_col_str.format(direction_val='{:.2f}'.format(dist))\n",
    "    body_html = body_html + header_template_str.format(header_row=header_inner_html)\n",
    "    \n",
    "    sample_row_html = ''\n",
    "    for sample_id in range(num_samples):\n",
    "          \n",
    "        sample_row_inner_html = sample_template_first_col_str.format(sample_id=sample_id)\n",
    "        for dist_id, dist in enumerate(distances, start=1):\n",
    "            sample_row_inner_html = sample_row_inner_html + sample_template_remaining_col_str.format(sample_id=sample_id, \\\n",
    "                                                                                                     semantic_id=sem_id, \\\n",
    "                                                                                                     dist=dist)\n",
    "        sample_row_html = sample_row_html + sample_row_inner_html\n",
    "    body_html = body_html + sample_template_str.format(sample_row=sample_row_html)\n",
    "    \n",
    "overall_html = overall_html_template_str.format(html_data=body_html)     \n",
    "with open(os.path.join(sefa_output_dir,'sefa.html'), 'w') as sefaf:\n",
    "    sefaf.write(overall_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pDL] *",
   "language": "python",
   "name": "conda-env-pDL-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
